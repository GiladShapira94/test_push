{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f114afa4",
   "metadata": {},
   "source": [
    "This notebook provides an overview of developing and deploying ML applications using MLRun and GitHub. \n",
    "\n",
    "Tutorial steps:\n",
    "\n",
    "1). Importing MLRun and creating a new project in MLRun\n",
    "2). Configuring Git (user name, user email and create git remotes with a specific branch)\n",
    "3). Developing and logging ML functions and artifacts -\n",
    "    a. Register a dataset artifact in the project for data_fetch function\n",
    "    b. Fetch Data func - register this function object into the project, run locally & remotely\n",
    "    c. Train Model func - register this function object into the project, run locally & remotely\n",
    "    d. Register a model artifact into the project\n",
    "    e. Deployment - build, test, deploy and register model serving function\n",
    "    f. Workflow - register a workflow (that will do steps c, e, f)\n",
    "4). Pushing project context to Git (end of the day)\n",
    "5). Pulling from Git to the project context(start of the day) and repeat from step 3 (if needed)\n",
    "Note: any of the sub-steps in step 3 are optional. Working with Git can also apply on just one of these sub-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adfdc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0042bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn==1.0.2 in /User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /conda/lib/python3.7/site-packages (from scikit-learn==1.0.2) (2.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/User/.pythonlibs/jupyter-shapira/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have the same version of the scikit-learn on the client as in the server (not needed in MLRun 1.3 or higher)\n",
    "! pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70bfa61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-03-08 08:57:48,752 [info] Deleting project new-git-project from MLRun DB due to overwrite\n",
      "> 2023-03-08 08:58:09,327 [info] Created and saved project new-git-project: {'from_template': None, 'overwrite': True, 'context': './', 'save': True}\n"
     ]
    }
   ],
   "source": [
    "# Create a new project. The init_git flag is used to initialize git in the context dir (makes a hidden .git directory)\n",
    "project = mlrun.new_project(name='new-git-project',init_git=True,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ac1e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: new-git-project\n",
      "spec:\n",
      "  functions: []\n",
      "  workflows: []\n",
      "  artifacts: []\n",
      "  source: git://github.com/GiladShapira94/test_push.git#refs/heads/master\n",
      "  origin_url: git://github.com/GiladShapira94/test_push.git#refs/heads/master\n",
      "  desired_state: online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A Light project YAML looks like\n",
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d88f99",
   "metadata": {},
   "source": [
    "If you are using containerized Jupyter you need to first set your Git parameters, using the following commands in MLRun CLI (The last command will not be needed at MLRun 1.3 as it will be part of the  .gitconfig file in the home directory)\n",
    "```\n",
    "git config --global user.email \"<my@email.com>\"\n",
    "git config --global user.name \"<name>\"\n",
    "git config --global credential.helper store\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c839d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this only once (before remote origin already exists)\n",
    "# project.create_remote(\"https://github.com/GiladShapira94/test_push.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9d4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register an artifact in the project, so that it can be further imported on project load  \n",
    "from mlrun.artifacts import DatasetArtifact\n",
    "data_url = 'https://s3.wasabisys.com/iguazio/data/iris/iris.data.raw.csv'\n",
    "# Register an artifact in the project (to be used in workflows) \n",
    "project.set_artifact('data', artifact=DatasetArtifact(),target_path=data_url,tag='v1')    \n",
    "project.register_artifacts() #saves the artifact in MLRun DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7265865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_art = project.get_artifact('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ba840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: dataset\n",
      "metadata:\n",
      "  key: data\n",
      "  project: new-git-project\n",
      "  iter: 0\n",
      "  tree: a31bc941542541fa7c70e4369297ea9872ab7539\n",
      "  tag: latest\n",
      "  updated: '2023-03-08T08:58:22.797676+00:00'\n",
      "spec:\n",
      "  target_path: https://s3.wasabisys.com/iguazio/data/iris/iris.data.raw.csv\n",
      "  format: ''\n",
      "  db_key: data\n",
      "  producer:\n",
      "    kind: project\n",
      "    name: new-git-project\n",
      "    tag: a31bc941542541fa7c70e4369297ea9872ab7539\n",
      "  sources: []\n",
      "  license: ''\n",
      "status:\n",
      "  state: created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_art.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33518b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the project YAML looks now\n",
    "# print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c373d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fetch_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fetch_data.py\n",
    "import mlrun\n",
    "@mlrun.handler(outputs=[\"dataset\",\"label_column\"])\n",
    "def fetch_data(dataset):\n",
    "    \"\"\"\n",
    "    A function which fetches data to MLRun\n",
    "    \"\"\"\n",
    "    df = dataset.as_df()\n",
    "    \n",
    "    return df, \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112bca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f1f836cfc10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a serverless function object from the code above, and register it in the project\n",
    "fetch_data_fn = project.set_function(\"fetch_data.py\", name=\"fetch_data\", kind=\"job\", image=\"mlrun/mlrun\", handler=\"fetch_data\")\n",
    "project.save()  # save the project with the latest config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8227b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the project YAML looks now\n",
    "# print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adeeaba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run locally for debugging (Optional step)\n",
    "# fetch_data_run_locally = project.run_function(\"fetch_data\",inputs={'dataset':project.get_artifact('data').uri}, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_data_run_locally.artifact(\"dataset\").as_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f0b102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-03-08 08:58:24,781 [info] starting run fetch-data-fetch_data uid=35839472f795472ba5d11e27d2b0005d DB=http://mlrun-api:8080\n",
      "> 2023-03-08 08:58:24,921 [info] Job is running in the background, pod: fetch-data-fetch-data-5jqlt\n",
      "> 2023-03-08 08:58:30,601 [info] To track results use the CLI: {'info_cmd': 'mlrun get run 35839472f795472ba5d11e27d2b0005d -p new-git-project', 'logs_cmd': 'mlrun logs 35839472f795472ba5d11e27d2b0005d -p new-git-project'}\n",
      "> 2023-03-08 08:58:30,601 [info] Or click for UI: {'ui_url': 'https://dashboard.default-tenant.app.cust-cs-il-3-5-2.iguazio-cd2.com/mlprojects/new-git-project/jobs/monitor/35839472f795472ba5d11e27d2b0005d/overview'}\n",
      "> 2023-03-08 08:58:30,602 [info] run executed, status=completed\n",
      "final state: completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>new-git-project</td>\n",
       "      <td><div title=\"35839472f795472ba5d11e27d2b0005d\"><a href=\"https://dashboard.default-tenant.app.cust-cs-il-3-5-2.iguazio-cd2.com/mlprojects/new-git-project/jobs/monitor/35839472f795472ba5d11e27d2b0005d/overview\" target=\"_blank\" >...d2b0005d</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Mar 08 08:58:28</td>\n",
       "      <td>completed</td>\n",
       "      <td>fetch-data-fetch_data</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=shapira</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=shapira</div><div class=\"dictlist\">mlrun/client_version=1.3.0-rc20</div><div class=\"dictlist\">mlrun/client_python_version=3.7.6</div><div class=\"dictlist\">host=fetch-data-fetch-data-5jqlt</div></td>\n",
       "      <td><div title=\"store://artifacts/new-git-project/data#0:a31bc941542541fa7c70e4369297ea9872ab7539\">dataset</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">label_column=label</div></td>\n",
       "      <td><div title=\"v3io:///projects/new-git-project/artifacts/fetch-data-fetch_data/0/dataset.parquet\">dataset</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultaf0dc5ac-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultaf0dc5ac-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultaf0dc5ac\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultaf0dc5ac-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> > to track results use the .show() or .logs() methods  or <a href=\"https://dashboard.default-tenant.app.cust-cs-il-3-5-2.iguazio-cd2.com/mlprojects/new-git-project/jobs/monitor/35839472f795472ba5d11e27d2b0005d/overview\" target=\"_blank\">click here</a> to open in UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-03-08 08:58:31,169 [info] run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "# Now run remotely \n",
    "fetch_data_run_remotely = project.run_function(\"fetch_data\",inputs={'dataset':project.get_artifact('data').uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0fe279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer.py\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlrun\n",
    "from mlrun.frameworks.sklearn import apply_mlrun\n",
    "\n",
    "\n",
    "@mlrun.handler()\n",
    "def train(\n",
    "    dataset: pd.DataFrame,\n",
    "    label_column: str = \"label\",\n",
    "    n_estimators: int = 100,\n",
    "    learning_rate: float = 0.1,\n",
    "    max_depth: int = 3,\n",
    "    model_name: str = \"iris_model\",\n",
    "):\n",
    "    # Initialize the x & y data\n",
    "    x = dataset.drop(label_column, axis=1)\n",
    "    y = dataset[label_column]\n",
    "    # print(sklearn.__version__)\n",
    "    \n",
    "    # Train/Test split the dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Pick an ideal ML model\n",
    "    model = ensemble.GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth\n",
    "    )\n",
    "\n",
    "    # -------------------- The only line you need to add for MLOps -------------------------\n",
    "    # Wraps the model with MLOps (test set is provided for analysis & accuracy measurements)\n",
    "    apply_mlrun(model=model, model_name=model_name, x_test=x_test, y_test=y_test)\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7979dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other option is to use the auto_trainer function form the hub:\n",
    "# trainer = project.set_function(func=\"hub://auto_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d139d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a serverless function object from the code above, and register it in the project\n",
    "trainer = project.set_function(func=\"trainer.py\", name=\"trainer\", kind=\"job\", image=\"mlrun/mlrun\", handler=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91deace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-03-08 08:58:31,309 [info] starting run trainer-train uid=5ff8b5d4507545d1b61a5f2ea7d18319 DB=http://mlrun-api:8080\n",
      "> 2023-03-08 08:58:31,446 [info] Job is running in the background, pod: trainer-train-c8sqt\n"
     ]
    }
   ],
   "source": [
    "#Run the function on the remote cluster (you can also run it locally at first by mentioning - local=True)\n",
    "trainer_run = project.run_function(\"trainer\",\n",
    "        inputs={\"dataset\": fetch_data_run_remotely.outputs[\"dataset\"]},\n",
    "        params = {\n",
    "            \"model_class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"train_test_split_size\": 0.2,\n",
    "            \"label_columns\": \"label\",\n",
    "            \"model_name\":'iris_model'}, handler='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ae12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results (metrics) and artifacts are generated and tracked automatically by MLRun\n",
    "# trainer_run.artifact('confusion-matrix').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539254a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a model artifact in the project, so that it can be further imported on project load\n",
    "from mlrun.artifacts import ModelArtifact\n",
    "project.set_artifact('model', ModelArtifact(model_file=\"iris_model.pkl\"), target_path='s3://mlrun/projects/new-git-proj/artifacts/trainer-train/0/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465bfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a model serving function\n",
    "serving_fn = mlrun.new_function(\"serving\", image=\"python:3.8\", kind=\"serving\", requirements=[\"mlrun[complete]\", \"scikit-learn==1.0.2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197db989",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_run.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a model to the serving function\n",
    "serving_fn.add_model('iris_model',model_path=trainer_run.outputs[\"model\"], class_name='mlrun.frameworks.sklearn.SklearnModelServer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating the model server locally\n",
    "server = serving_fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the mock model server endpoint\n",
    "# server.test(\"/v2/models/\", method=\"GET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306731e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer using test data\n",
    "my_data = {\"inputs\"\n",
    "           :[[\n",
    "               5,3,1.5,0.2]\n",
    "            ]\n",
    "}\n",
    "server.test(\"/\", body=my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620b3b7",
   "metadata": {},
   "source": [
    "Deploy a real-time serving function (over K8S or Docker). This requires Nuclio to be installed (over K8S or Docker).\n",
    "Use the mlrun deploy_function() method to build and deploy a Nuclio serving function from your serving-function code\n",
    "Use the mlrun deploy_function() method to build and deploy a Nuclio serving function from your serving-function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.deploy_function(serving_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the live endpoint\n",
    "serving_fn.invoke(\"/\", body=my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9292a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before registering the serving function in the project (so that it can be further loaded from git) we first exporting\n",
    "# its YAML, so that project YAML will look more compact (otherwise it will include the whole YAML of the serving function)\n",
    "serving_fn.export('serving.yaml')\n",
    "project.set_function(func='serving.yaml',name='serving',kind='serving')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff563788",
   "metadata": {},
   "source": [
    "For setting a nuclio function you can see the example below:\n",
    "```\n",
    "project.set_function(func='nuclio.py',name='nuclio',handler='multi:multi_3',kind='nuclio',image='mlrun/mlrun')\n",
    "Or\n",
    "project.set_function(name='nuclio',handler='multi:multi_3',kind='nuclio',image='mlrun/mlrun',with_repo=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7140d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how the project YAML looks now\n",
    "# print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece7fed",
   "metadata": {},
   "source": [
    "Build and run automated ML pipelines and CI/CD\n",
    "\n",
    "A pipeline is created by running an MLRun “workflow”. The following code defines a workflow and \n",
    "writes it to a file in your local directory, with the file name workflow.py. The workflow describes\n",
    "a directed acyclic graph (DAG) which is executed using the local, remote, or kubeflow engines.\n",
    "\n",
    "See \"running a multi-stage workflow\". The defined pipeline includes the following steps:\n",
    "Generate/prepare the data (fetch).\n",
    "Train and the model (train).\n",
    "Deploy the model as a real-time serverless function (serving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile './workflow.py'\n",
    "\n",
    "from kfp import dsl\n",
    "import mlrun\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(name=\"iris-git-demo\")\n",
    "def pipeline(dataset_uri,model_name=\"iris_model\"):\n",
    "    # Run the ingestion function with the new image and params\n",
    "    ingest = mlrun.run_function(inputs={'dataset':dataset_uri},\n",
    "        function=\"fetch_data\",\n",
    "        outputs=[\"dataset\"], \n",
    "    )\n",
    "\n",
    "    # Train a model using the trainer function\n",
    "    train = mlrun.run_function(\n",
    "        \"trainer\",\n",
    "        inputs={\"dataset\": ingest.outputs[\"dataset\"]},\n",
    "        params = {\n",
    "            \"model_class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"train_test_split_size\": 0.2,\n",
    "            \"label_columns\": \"label\",\n",
    "            \"model_name\": model_name,\n",
    "        }, \n",
    "        handler='train',\n",
    "        outputs=[\"model\"],\n",
    "    )\n",
    "\n",
    "    # Deploy the trained model as a serverless function\n",
    "    mlrun.deploy_function(\n",
    "        \"serving\",\n",
    "        models=[\n",
    "            {\n",
    "                \"key\": model_name,\n",
    "                \"model_path\": train.outputs[\"model\"],\n",
    "                \"class_name\": 'mlrun.frameworks.sklearn.SklearnModelServer',\n",
    "            }\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cde2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a multi-stage workflow (./workflow.py) to the project with the name 'main' and save the project \n",
    "my_workflow = project.set_workflow('main', \"./workflow.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow\n",
    "run_id = project.run(\n",
    "    #workflow_path=\"./workflow.py\",\n",
    "    name = 'main',\n",
    "    arguments={'dataset_uri':project.get_artifact('data').uri}, \n",
    "    watch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bcf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how project YAML looks now\n",
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49adde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pull the latest code from git (important if remote changed)\n",
    "# project.pull(\"master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default project.push pushes the project.yaml, so there is no need to include it in files_to_add\n",
    "files_to_add = ['main.ipynb','fetch_data.py','serving.yaml','trainer.py','workflow.py','test.txt']\n",
    "# Save the project state and commit/push updates to the remote git repo with all the files in files_to_add\n",
    "project.push(branch='master',message='project with a workflow',add=files_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543395a0",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully pushed your poject to git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is needed if the remote code changed after my push (e.g a team is working on the same branch)\n",
    "project.pull(\"my_git_project\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aab6b2",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully pulled your poject from git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
